【網站標題 / 主視覺標語】

柯德瑋 (Te-Wei Ko) — 情感運算與多模態互動研究者
致力於工程化同理心，探索敘事、感知與現實的邊界。

【關於我 (About Me) / 研究哲學 (Research Philosophy)】

我是柯德瑋，一名探索「體驗」本質的資工學者。我的研究核心，是探討如何利用科技，跨越人類溝通的最終疆界——將抽象的「情感」與「同理心」，轉譯為可被直接感知的物理訊號。

我相信，下一代的運算平台，將不再僅僅是處理資訊的工具，而是深化人類連結、擴展感知維度的媒介。我的使命，是結合情感運算、生成式 AI 與互動設計，建立能夠理解並生成深度沉浸式體驗的框架，並為所有使用者，特別是身障與弱勢族群，打造一個更具包容性的數位世界。

【研究組合 (Research Portfolio)】

在這裡，我將展示一系列旨在探索「工程化同理心」核心理念的代表性計畫。

[ 專案一 ] Project H.O.L.O.: A Neuro-Semantic Framework for Multi-Modal Narrative Immersion

作為我研究藍圖的起點，Project H.O.L.O. 旨在將傳統的、單向的閱讀，升級為一場多重感官的沉浸式敘事體驗。它不僅是一個產品原型，更是一個用以驗證「生成-分析」情感回饋閉環的實驗平台。

核心功能：僅需書籍封面，即可動態生成富有情感層次的 Podcast 內容，並同步輸出觸覺、嗅覺等感官訊號。

研究價值：探索如何量化「生成式」感官體驗與使用者「真實」情感反應之間的保真度，並建立動態校準模型。

關鍵技術：

影像辨識 (ResNet/ViT), 大型語言模型 (LLMs/RAG), 多模態輸出 (TTS/Haptics), 無障礙UI設計 (WAI-ARIA)。

深度語意分析：使用自然語言處理 (NLP) 技術，將文本解構為語意單元，並分析情感、語調、角色關係與故事背景。

生成式 AI：基於語意單元創建動態的聽覺體驗，並使用文本到聲音 (Text-to-Sound) 與文本到氣味 (Text-to-Scent) 的生成技術。

多模態感知系統：整合聽覺、觸覺與嗅覺回饋，並開發 API 供硬體設備使用。

[ 專案二 ]

（此處留白，為您未來的瘋狂計畫預留空間）

[ 專案三 ]

（此處留白，為您未來的瘋狂計畫預留空間）

【研究興趣 (Research Interests)】

情感運算 (Affective Computing)

多模態人機互動 (Multimodal HCI)

計算敘事學 (Computational Narrative)

生成式人工智慧 (Generative AI)

數位平權與無障礙設計 (Digital Equity & Accessibility)

【核心技能 (Skills)】

程式語言： Python, C++, Swift, Java

AI / ML 框架： TensorFlow, PyTorch, Scikit-learn

專業領域： 機器學習模型設計、自然語言處理、訊號處理、系統架構

語言： 中文 (母語), 英文 (流利)

【聯絡方式 (Contact)】

Email: 4b4g0077@stust.edu.tw / 4b4g0077@office.stust.edu.tw

電話: 0981614900

GitHub: https://github.com/STUST-KOTEWEI

【授權 (License)】

此專案使用 MIT 授權條款 - 詳見 [LICENSE](LICENSE) 檔案。
